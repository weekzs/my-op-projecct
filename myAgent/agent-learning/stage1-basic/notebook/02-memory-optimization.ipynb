{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ äº’åŠ¨å®éªŒï¼šAgentè®°å¿†ä¼˜åŒ–\n",
    "\n",
    "## ğŸ§ª å®éªŒç›®æ ‡\n",
    "\n",
    "åœ¨è¿™ä¸ªNotebookä¸­ï¼Œä½ å°†æ·±å…¥å®éªŒAgentçš„è®°å¿†ç®¡ç†ï¼ŒåŒ…æ‹¬ï¼š\n",
    "- æµ‹è¯•ä¸åŒè®°å¿†ç­–ç•¥çš„æ•ˆæœ\n",
    "- ä¼˜åŒ–è®°å¿†çª—å£å¤§å°\n",
    "- å®ç°å…³é”®ä¿¡æ¯æå–\n",
    "- å¯¹æ¯”ä¸åŒç­–ç•¥çš„Tokenæ¶ˆè€—\n",
    "\n",
    "## ğŸš€ å¼€å§‹å®éªŒ\n",
    "\n",
    "é¦–å…ˆï¼Œè®©æˆ‘ä»¬å¯¼å…¥å¿…è¦çš„åº“å¹¶è®¾ç½®ç¯å¢ƒã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ å·²æ·»åŠ è·¯å¾„: d:\\BaiduSyncdisk\\learning\\cursor\\myGithub\\myAgent\\agent-learning\\stage1-basic\n",
      "ğŸ”§ ç¯å¢ƒé…ç½®å®Œæˆ\n",
      "Model: gpt-3.5-turbo\n",
      "Base URL: https://api.chatanywhere.tech/v1\n",
      "âœ… ç±»å¯¼å…¥æˆåŠŸï¼šSimpleChatAgent, MemoryChatAgent, SlidingWindowMemory\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥åŸºç¡€åº“\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥æ¨¡å—\n",
    "# è·å– stage1-basic ç›®å½•çš„ç»å¯¹è·¯å¾„\n",
    "# åœ¨ Jupyter Notebook ä¸­ï¼Œå·¥ä½œç›®å½•é€šå¸¸æ˜¯é¡¹ç›®æ ¹ç›®å½•æˆ– notebook ç›®å½•\n",
    "# æˆ‘ä»¬éœ€è¦æ‰¾åˆ° stage1-basic ç›®å½•\n",
    "import pathlib\n",
    "\n",
    "# æ–¹æ³•1ï¼šå°è¯•ä»å½“å‰å·¥ä½œç›®å½•å‘ä¸ŠæŸ¥æ‰¾\n",
    "cwd = pathlib.Path.cwd()\n",
    "stage1_dir = None\n",
    "\n",
    "# å¦‚æœå½“å‰åœ¨ notebook ç›®å½•ï¼Œå‘ä¸Šæ‰¾åˆ° stage1-basic\n",
    "if cwd.name == 'notebook':\n",
    "    stage1_dir = cwd.parent\n",
    "elif 'stage1-basic' in str(cwd):\n",
    "    # å¦‚æœå·²ç»åœ¨ stage1-basic ç›®å½•\n",
    "    stage1_dir = cwd if cwd.name == 'stage1-basic' else cwd / 'stage1-basic'\n",
    "else:\n",
    "    # å°è¯•æŸ¥æ‰¾ stage1-basic ç›®å½•\n",
    "    for parent in cwd.parents:\n",
    "        if parent.name == 'stage1-basic':\n",
    "            stage1_dir = parent\n",
    "            break\n",
    "    if stage1_dir is None:\n",
    "        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå‡è®¾å½“å‰ç›®å½•å°±æ˜¯ stage1-basic\n",
    "        stage1_dir = cwd\n",
    "\n",
    "# æ·»åŠ åˆ° sys.path\n",
    "if stage1_dir and str(stage1_dir) not in sys.path:\n",
    "    sys.path.insert(0, str(stage1_dir))\n",
    "    print(f\"ğŸ“ å·²æ·»åŠ è·¯å¾„: {stage1_dir}\")\n",
    "else:\n",
    "    print(f\"ğŸ“ ä½¿ç”¨è·¯å¾„: {stage1_dir}\")\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# ä» Python æ¨¡å—å¯¼å…¥ç±»ï¼ˆä¸æ˜¯ä» notebook æ–‡ä»¶å¯¼å…¥ï¼‰\n",
    "from simple_chat import SimpleChatAgent\n",
    "from memory_chat import MemoryChatAgent, SlidingWindowMemory\n",
    "\n",
    "print(\"ğŸ”§ ç¯å¢ƒé…ç½®å®Œæˆ\")\n",
    "print(f\"Model: {os.getenv('MODEL_NAME', 'qwen-max')}\")\n",
    "print(f\"Base URL: {os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')}\")\n",
    "print(\"âœ… ç±»å¯¼å…¥æˆåŠŸï¼šSimpleChatAgent, MemoryChatAgent, SlidingWindowMemory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  å®éªŒ1ï¼šå…³é”®ä¿¡æ¯æå–è®°å¿†\n",
    "\n",
    "æ»‘åŠ¨çª—å£ç­–ç•¥å¯èƒ½ä¼šä¸¢å¤±é‡è¦ä¿¡æ¯ã€‚è®©æˆ‘ä»¬å®ç°ä¸€ä¸ªæ›´æ™ºèƒ½çš„è®°å¿†ç­–ç•¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å…³é”®ä¿¡æ¯è®°å¿†ç³»ç»Ÿå·²åˆ›å»º\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰ä¸€ä¸ªå…³é”®ä¿¡æ¯è®°å¿†çš„ç±»ï¼Œç”¨äºæå–å’Œå­˜å‚¨ç”¨æˆ·çš„å…³é”®ä¿¡æ¯å’Œè¿‘æœŸå¯¹è¯\n",
    "class KeyInfoMemory:\n",
    "    \"\"\"\n",
    "    å…³é”®ä¿¡æ¯æå–è®°å¿†ç­–ç•¥\n",
    "    ä¿ç•™é‡è¦ä¿¡æ¯ï¼Œæ»‘åŠ¨ä¿ç•™æœ€è¿‘å¯¹è¯\n",
    "    \"\"\"\n",
    "    \n",
    "    # æ„é€ å‡½æ•°ï¼Œåˆå§‹åŒ–çª—å£å¤§å°å’Œå¿…è¦æ•°æ®ç»“æ„\n",
    "    def __init__(self, window_size=3):\n",
    "        # ä¿å­˜æ»‘åŠ¨çª—å£å¤§å°ï¼Œç±»å‹ä¸ºintï¼Œé»˜è®¤ä¸º3\n",
    "        self.window_size = window_size\n",
    "        # åˆå§‹åŒ–å…³é”®ä¿¡æ¯çš„å­—å…¸ï¼Œç”¨äºä¿å­˜ç”¨æˆ·é‡è¦å±æ€§\n",
    "        self.key_info = {}\n",
    "        # åˆå§‹åŒ–æœ€è¿‘å¯¹è¯çš„åˆ—è¡¨ï¼Œç”¨äºä¿å­˜æ»‘åŠ¨çª—å£èŒƒå›´å†…çš„å¯¹è¯å†å²\n",
    "        self.recent_conversations = []\n",
    "        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œç”¨äºä¸LLMæ¨¡å‹è¿›è¡Œäº¤äº’è°ƒç”¨\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),  # ä»ç¯å¢ƒå˜é‡è·å–OpenAIçš„APIå¯†é’¥\n",
    "            base_url=os.getenv(\"OPENAI_BASE_URL\") # ä»ç¯å¢ƒå˜é‡è·å–APIçš„åŸºç¡€URL\n",
    "        )\n",
    "    \n",
    "    # å®šä¹‰ä»æ¶ˆæ¯å†…å®¹ä¸­æå–å…³é”®ä¿¡æ¯çš„æ–¹æ³•\n",
    "    def extract_key_info(self, message):\n",
    "        \"\"\"ä»æ¶ˆæ¯ä¸­æå–å…³é”®ä¿¡æ¯\"\"\"\n",
    "        try:\n",
    "            # æ„é€ promptï¼Œè¦æ±‚å¤§æ¨¡å‹ä»…ä»¥JSONæ ¼å¼æŠ½å–å…³é”®ä¿¡æ¯ï¼Œä¸è¦å…¶ä»–æ–‡å­—\n",
    "            # è¿™æ˜¯ Python 3.6 åŠä»¥ä¸Šæ”¯æŒçš„ f-stringï¼ˆæ ¼å¼åŒ–å­—ç¬¦ä¸²å­—é¢é‡ï¼‰è¯­æ³•ï¼Œ\n",
    "            # ç”¨äºåœ¨å­—ç¬¦ä¸²ä¸­åµŒå…¥å˜é‡æˆ–è¡¨è¾¾å¼ã€‚åœ¨å­—ç¬¦ä¸²å‰åŠ  fï¼Œå†åœ¨å­—ç¬¦ä¸²å†…éƒ¨ç”¨ {å˜é‡å} çš„æ–¹å¼å³å¯å°†å˜é‡å€¼åµŒå…¥åˆ°å­—ç¬¦ä¸²é‡Œã€‚\n",
    "            # æ”¯æŒå¤šè¡Œå­—ç¬¦ä¸²ï¼ˆç”¨ä¸‰ä¸ªå¼•å·ï¼‰ï¼Œå¹¶èƒ½è‡ªåŠ¨æ ¼å¼åŒ–å˜é‡ä¸ºå­—ç¬¦ä¸²ã€‚\n",
    "            #\n",
    "            # ä¾‹å¦‚ï¼š\n",
    "            # name = \"Alice\"\n",
    "            # age = 18\n",
    "            # s = f\"å§“å:{name}, å¹´é¾„:{age+1}\"\n",
    "            # print(s)\n",
    "            # # è¾“å‡º: å§“å:Alice, å¹´é¾„:19\n",
    "            #\n",
    "            prompt = f\"\"\"\n",
    "            ä»ä»¥ä¸‹æ¶ˆæ¯ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œåªè¿”å›JSONæ ¼å¼ï¼š\n",
    "            {{\n",
    "              \"name\": \"å§“å(å¦‚æœæœ‰)\",\n",
    "              \"location\": \"åœ°ç‚¹(å¦‚æœæœ‰)\",\n",
    "              \"job\": \"èŒä¸š(å¦‚æœæœ‰)\",\n",
    "              \"preference\": \"åå¥½/çˆ±å¥½(å¦‚æœæœ‰)\"\n",
    "            }}\n",
    "            \n",
    "            æ¶ˆæ¯ï¼š{message}\n",
    "            \n",
    "            åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–æ–‡å­—ï¼š\n",
    "            \"\"\"\n",
    "            \n",
    "            # é€šè¿‡OpenAIçš„Chatæ¥å£è¿›è¡Œè¯·æ±‚ï¼Œè®¾ç½®ç²¾åº¦å‚æ•°ï¼ˆtemperatureï¼‰ï¼Œé™åˆ¶è¾“å‡ºæœ€å¤§tokens\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=os.getenv(\"MODEL_NAME\", \"qwen-max\"),  # æŒ‡å®šè¦è°ƒç”¨çš„æ¨¡å‹\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],  # ä»¥å¯¹è¯æ ¼å¼æä¾›prompt\n",
    "                temperature=0.1,  # æ¸©åº¦ä½ä»£è¡¨ç­”æ¡ˆæ›´ç¨³å®š\n",
    "                max_tokens=100    # é™åˆ¶æœ€å¤šç”Ÿæˆçš„tokenæ•°é‡\n",
    "            )\n",
    "            \n",
    "            # ä»è¿”å›çš„responseç»“æ„ä½“é‡Œè·å–æ¨¡å‹è¾“å‡ºå†…å®¹ï¼Œå¹¶ç§»é™¤é¦–å°¾ç©ºæ ¼\n",
    "            content = response.choices[0].message.content.strip()\n",
    "            # å¯¹ç»“æœå†…å®¹åšæ¸…ç†ï¼Œå»æ‰å¯èƒ½çš„markdownä»£ç å—å¼€å¤´å’Œç»“å°¾ï¼ˆå¦‚```json ... ```ï¼‰\n",
    "            content = re.sub(r'```json\\n?', '', content).replace('```', '')\n",
    "            \n",
    "            # ä½¿ç”¨json.loadså°†å­—ç¬¦ä¸²è§£æä¸ºPythonå­—å…¸\n",
    "            info = json.loads(content)\n",
    "            \n",
    "            # éå†æŠ½å–å‡ºæ¥çš„ä¿¡æ¯ï¼Œå¦‚æœæœ‰å€¼å°±å†™å…¥/è¦†ç›–å½“å‰key_infoå­—å…¸\n",
    "            for key, value in info.items():\n",
    "                # åˆ¤æ–­valueéç©ºä¸”æ’é™¤\"(å¦‚æœæœ‰)\"ç­‰æ¨¡æ¿æ®‹ç•™\n",
    "                if value and value.strip() and value != \"(å¦‚æœæœ‰)\":\n",
    "                    self.key_info[key] = value.strip()\n",
    "                    \n",
    "            # è¿”å›Trueè¡¨ç¤ºæˆåŠŸ\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            # æ•è·å¼‚å¸¸å¹¶æ‰“å°å¤±è´¥åŸå› \n",
    "            print(f\"æå–å…³é”®ä¿¡æ¯å¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # æ›´æ–°è®°å¿†çš„æ–¹æ³•ï¼Œroleä¸º\"ç”¨æˆ·\"æˆ–\"åŠ©æ‰‹\"ï¼Œcontentä¸ºæ¶ˆæ¯æ–‡æœ¬\n",
    "    def update(self, role, content):\n",
    "        \"\"\"æ›´æ–°è®°å¿†\"\"\"\n",
    "        # å¦‚æœå½“å‰æ¶ˆæ¯æ˜¯ç”¨æˆ·å‘çš„ï¼Œåˆ™å°è¯•æå–å…³é”®ä¿¡æ¯\n",
    "        if role == \"user\":\n",
    "            self.extract_key_info(content)\n",
    "            \n",
    "        # å°†èŠå¤©å†…å®¹ä»¥å­—å…¸å½¢å¼è¿½åŠ åˆ°æœ€è¿‘å¯¹è¯åˆ—è¡¨ä¸­\n",
    "        self.recent_conversations.append({\"role\": role, \"content\": content})\n",
    "        \n",
    "        # è¿™é‡Œè®¾ç½®æœ€è¿‘å¯¹è¯çš„æ»‘åŠ¨çª—å£æœ€å¤§é•¿åº¦ä¸ºwindow_size*2ï¼Œæ²¡æœ‰åŠ 1ï¼Œ\n",
    "        # å› ä¸ºæ¯æ¬¡æ— è®ºæ˜¯ç”¨æˆ·è¿˜æ˜¯åŠ©æ‰‹çš„æ¶ˆæ¯éƒ½ä¼šå„è‡ªappendä¸€æ¬¡ï¼Œwindow_sizeæŒ‰ä¸€è½®åŒäººå¯¹è¯è®¡ï¼›\n",
    "        # å¦‚æœæƒ³ä¸€è½®åŒ…å«â€œç”¨æˆ·+åŠ©æ‰‹â€æ¶ˆæ¯ï¼Œå¯ä»¥ç”¨*2è€Œä¸æ˜¯*2+1ã€‚ä¾‹å¦‚window_size=3ï¼Œåˆ™æœ€å¤šä¿ç•™6æ¡ï¼ˆåˆšå¥½3è½®ï¼‰ï¼Œæ— éœ€+1ã€‚\n",
    "        max_recent = self.window_size * 2\n",
    "        # å¦‚æœå¯¹è¯ç¼“å­˜è¶…è¿‡çª—å£é•¿åº¦ï¼Œåˆ™åªä¿ç•™æœ€æ–°Næ¡\n",
    "        if len(self.recent_conversations) > max_recent:\n",
    "            # Pythonçš„åˆ‡ç‰‡[-N:]è¯­æ³•ï¼Œå–æœ€è¿‘Næ¡æ¶ˆæ¯\n",
    "            self.recent_conversations = self.recent_conversations[-max_recent:]\n",
    "    \n",
    "    # è·å–å¸¦æœ‰å…³é”®ä¿¡æ¯+è¿‘æœŸæ¶ˆæ¯çš„å®Œæ•´ä¸Šä¸‹æ–‡ï¼Œç”¨ä½œæ¨¡å‹è¾“å…¥\n",
    "    def get_context(self):\n",
    "        \"\"\"æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡\"\"\"\n",
    "        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡åˆ—è¡¨\n",
    "        context = []\n",
    "        \n",
    "        # å¦‚æœå·²å­˜æœ‰å…³é”®ä¿¡æ¯ï¼Œåˆ™ç»„ç»‡ç³»ç»Ÿæç¤ºï¼Œå¦åˆ™ç”¨é»˜è®¤æç¤º\n",
    "        if self.key_info:\n",
    "            # ç”¨åˆ—è¡¨æ¨å¯¼å’Œjoinï¼Œå°†å…³é”®ä¿¡æ¯æ ¼å¼åŒ–ä¸º\"key: value\"å­—ç¬¦ä¸²\n",
    "            key_info_str = \", \".join([f\"{k}: {v}\" for k, v in self.key_info.items()])\n",
    "            # æ‹¼æ¥ç³»ç»Ÿæç¤ºï¼ŒæŒ‡æ˜ç”¨æˆ·ä¿¡æ¯\n",
    "            system_prompt = f\"ä½ æ˜¯ä¸€ä¸ªæœ‰è®°å¿†çš„åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯ç”¨æˆ·çš„é‡è¦ä¿¡æ¯ï¼š{key_info_str}ã€‚è®°ä½è¿™äº›ä¿¡æ¯å¹¶åœ¨å¯¹è¯ä¸­é€‚å½“ä½¿ç”¨ã€‚\"\n",
    "        else:\n",
    "            # æ²¡æœ‰å…³é”®ä¿¡æ¯æ—¶ï¼Œç”¨é€šç”¨å‹å¥½æç¤º\n",
    "            system_prompt = \"ä½ æ˜¯ä¸€ä¸ªæœ‰è®°å¿†çš„å‹å¥½åŠ©æ‰‹ã€‚\"\n",
    "        \n",
    "        # å°†ç³»ç»Ÿæç¤ºä½œä¸ºsystemè§’è‰²å¯¹è¯æ·»åŠ åˆ°ä¸Šä¸‹æ–‡å¼€å¤´\n",
    "        context.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        \n",
    "        # ç”¨list.extendæŠŠæœ€è¿‘å¯¹è¯åŠ å…¥ä¸Šä¸‹æ–‡ï¼ˆlistæ‹¼æ¥è¯­æ³•è¯´æ˜ï¼‰\n",
    "        context.extend(self.recent_conversations)\n",
    "        \n",
    "        # è¿”å›æœ€ç»ˆä¸Šä¸‹æ–‡\n",
    "        return context\n",
    "    \n",
    "    # è·å–å½“å‰è®°å¿†çŠ¶æ€çš„ç»Ÿè®¡ä¿¡æ¯\n",
    "    def get_stats(self):\n",
    "        \"\"\"è·å–ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        # è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…æ‹¬å…³é”®ä¿¡æ¯æ•°ã€å¯¹è¯æ•°ã€æ‹·è´çš„å…³é”®ä¿¡æ¯å’Œçª—å£å¤§å°\n",
    "        return {\n",
    "            \"key_info_count\": len(self.key_info),                    # å…³é”®ä¿¡æ¯é¡¹çš„æ•°é‡\n",
    "            \"recent_messages\": len(self.recent_conversations),       # æœ€è¿‘çª—å£çš„æ¶ˆæ¯æ•°é‡\n",
    "            \"key_info\": self.key_info.copy(),                        # å…³é”®ä¿¡æ¯çš„å­—å…¸ï¼ˆæ·±æ‹·è´ï¼‰\n",
    "            \"window_size\": self.window_size                          # å½“å‰æ»‘åŠ¨çª—å£å¤§å°\n",
    "        }\n",
    "\n",
    "# å®šä¹‰åŸºäºå…³é”®ä¿¡æ¯è®°å¿†çš„èŠå¤©åŠ©æ‰‹ç±»\n",
    "class KeyInfoChatAgent:\n",
    "    # æ„é€ æ–¹æ³•ï¼Œåˆå§‹åŒ–è‡ªå·±çš„è®°å¿†å®ä¾‹å’ŒOpenAIå®¢æˆ·ç«¯\n",
    "    def __init__(self, window_size=3):\n",
    "        # åˆ›å»ºä¸€ä¸ªKeyInfoMemoryå®ä¾‹ï¼Œç”¨äºå†…éƒ¨è®°å¿†ç®¡ç†\n",
    "        self.memory = KeyInfoMemory(window_size)\n",
    "        # åˆ›å»ºOpenAIå®¢æˆ·ç«¯ï¼Œç”¨äºåç»­ä¸å¤§æ¨¡å‹æ¥å£äº¤äº’\n",
    "        self.client = OpenAI(\n",
    "            api_key=os.getenv(\"OPENAI_API_KEY\"),  # è·å–API_KEY\n",
    "            base_url=os.getenv(\"OPENAI_BASE_URL\") # è·å–åŸºç¡€URL\n",
    "        )\n",
    "    \n",
    "    # èŠå¤©æ–¹æ³•ï¼Œè¾“å…¥ç”¨æˆ·æ¶ˆæ¯ï¼Œè¿”å›å›å¤\n",
    "    def chat(self, message):\n",
    "        try:\n",
    "            # æ›´æ–°è®°å¿†ï¼šæŠŠæœ¬è½®ç”¨æˆ·æ¶ˆæ¯å†™å…¥å†…éƒ¨è®°å¿†\n",
    "            self.memory.update(\"user\", message)\n",
    "            \n",
    "            # è·å–ç”¨äºä¸Šä¸‹æ–‡çš„æœ€è¿‘èŠå¤©å†å²+å…³é”®ä¿¡æ¯\n",
    "            context = self.memory.get_context()\n",
    "            \n",
    "            # å‘OpenAIæ¥å£å‘èµ·è¯·æ±‚ï¼Œå‘é€å®Œæ•´ä¸Šä¸‹æ–‡\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=os.getenv(\"MODEL_NAME\", \"qwen-max\"),  # æŒ‡å®šèŠå¤©æ¨¡å‹åç§°\n",
    "                messages=context,                           # ä¸Šä¸‹æ–‡æ¶ˆæ¯å†å²\n",
    "                temperature=0.3,                            # ç”Ÿæˆå›ç­”çš„å¤šæ ·æ€§\n",
    "                max_tokens=300                              # é™åˆ¶æœ€å¤§ç”Ÿæˆtokenæ•°\n",
    "            )\n",
    "            \n",
    "            # è·å–å¤§æ¨¡å‹è¿”å›çš„åŠ©æ‰‹æ¶ˆæ¯æ–‡æœ¬\n",
    "            assistant_msg = response.choices[0].message.content\n",
    "            # æŠŠåŠ©æ‰‹çš„å›å¤å†™å…¥è®°å¿†ï¼ˆè§’è‰²ä¸ºassistantï¼‰\n",
    "            self.memory.update(\"assistant\", assistant_msg)\n",
    "            \n",
    "            # è¿”å›ä¸€ä¸ªç»“æ„ä½“ï¼ŒåŒ…å«å›å¤å†…å®¹ã€æ¶ˆè€—tokenæ•°å’Œå½“å‰è®°å¿†ç»Ÿè®¡ä¿¡æ¯\n",
    "            return {\n",
    "                \"response\": assistant_msg,\n",
    "                \"tokens_used\": response.usage.total_tokens,\n",
    "                \"memory_stats\": self.memory.get_stats()\n",
    "            }\n",
    "        except Exception as e:\n",
    "            # æ•è·é”™è¯¯ï¼Œè¿”å›å¼‚å¸¸è¯´æ˜\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "# æ‰“å°å…³é”®ä¿¡æ¯è®°å¿†ç³»ç»Ÿå·²åˆ›å»ºï¼Œç”¨äºè°ƒè¯•ä¸æç¤º\n",
    "print(\"âœ… å…³é”®ä¿¡æ¯è®°å¿†ç³»ç»Ÿå·²åˆ›å»º\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§ª å¯¹æ¯”ä¸‰ç§è®°å¿†ç­–ç•¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” å¯¹æ¯”ä¸‰ç§è®°å¿†ç­–ç•¥\n",
      "============================================================\n",
      "\n",
      "ğŸ¤– 1. ç®€å•åŠ©æ‰‹ï¼ˆæ— è®°å¿†ï¼‰\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ğŸ§  2. æ»‘åŠ¨çª—å£è®°å¿†\n",
      "----------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# æµ‹è¯•å¯¹è¯åºåˆ—\n",
    "test_conversation = [\n",
    "    \"ä½ å¥½ï¼Œæˆ‘å«æåï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆã€‚\",\n",
    "    \"æˆ‘ä½åœ¨æ·±åœ³å—å±±ï¼Œå–œæ¬¢æ‰“ç¯®çƒå’Œçœ‹ä¹¦ã€‚\",\n",
    "    \"æˆ‘æ­£åœ¨å­¦ä¹ AIæŠ€æœ¯ï¼Œå¯¹Agentå¼€å‘å¾ˆæ„Ÿå…´è¶£ã€‚\",\n",
    "    \"æˆ‘çš„ç›®æ ‡æ˜¯æˆä¸ºä¸€åAIä¸“å®¶ã€‚\",\n",
    "    \"ä½ è§‰å¾—æˆ‘åº”è¯¥ä»å“ªé‡Œå¼€å§‹å­¦èµ·ï¼Ÿ\",\n",
    "    \"å¯¹äº†ï¼Œæˆ‘åˆšæ‰è¯´æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\",\n",
    "    \"æˆ‘ä½åœ¨å“ªä¸ªåŸå¸‚ï¼Ÿ\",\n",
    "    \"æˆ‘çš„èŒä¸šæ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"æˆ‘æœ‰ä»€ä¹ˆçˆ±å¥½ï¼Ÿ\",\n",
    "    \"è¯·ç»™æˆ‘ä¸€äº›å­¦ä¹ å»ºè®®ã€‚\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ” å¯¹æ¯”ä¸‰ç§è®°å¿†ç­–ç•¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. ç®€å•åŠ©æ‰‹ï¼ˆæ— è®°å¿†ï¼‰\n",
    "print(\"\\nğŸ¤– 1. ç®€å•åŠ©æ‰‹ï¼ˆæ— è®°å¿†ï¼‰\")\n",
    "print(\"-\" * 40)\n",
    "simple_agent = SimpleChatAgent()\n",
    "simple_results = []\n",
    "for i, msg in enumerate(test_conversation[-5:], 6):  # åªæµ‹è¯•å5ä¸ªé—®é¢˜\n",
    "    result = simple_agent.chat(msg)\n",
    "    simple_results.append(result)\n",
    "    print()\n",
    "\n",
    "# 2. æ»‘åŠ¨çª—å£è®°å¿†\n",
    "print(\"\\nğŸ§  2. æ»‘åŠ¨çª—å£è®°å¿†\")\n",
    "print(\"-\" * 40)\n",
    "window_agent = MemoryChatAgent(window_size=3)\n",
    "window_results = []\n",
    "for msg in test_conversation:\n",
    "    result = window_agent.chat(msg)\n",
    "    window_results.append(result)\n",
    "    if \"åå­—\" in msg or \"åŸå¸‚\" in msg or \"èŒä¸š\" in msg or \"çˆ±å¥½\" in msg:\n",
    "        # ä¿®å¤ï¼šå…ˆåˆ¤æ–­memory_statsçš„ç±»å‹ï¼ˆé¿å…TypeErrorï¼‰\n",
    "        stats = result.get('memory_stats')\n",
    "        if isinstance(stats, dict) and 'total_messages' in stats:\n",
    "            print(f\"ğŸ“Š è®°å¿†çŠ¶æ€: {stats['total_messages']}æ¡æ¶ˆæ¯\")\n",
    "        else:\n",
    "            print(\"ğŸ“Š è®°å¿†çŠ¶æ€: ï¼ˆæ— ç»Ÿè®¡æ•°æ®ï¼‰\")\n",
    "    print()\n",
    "\n",
    "# 3. å…³é”®ä¿¡æ¯è®°å¿†\n",
    "print(\"\\nğŸ¯ 3. å…³é”®ä¿¡æ¯è®°å¿†\")\n",
    "print(\"-\" * 40)\n",
    "keyinfo_agent = KeyInfoChatAgent(window_size=3)\n",
    "keyinfo_results = []\n",
    "for msg in test_conversation:\n",
    "    result = keyinfo_agent.chat(msg)\n",
    "    keyinfo_results.append(result)\n",
    "    if \"åå­—\" in msg or \"åŸå¸‚\" in msg or \"èŒä¸š\" in msg or \"çˆ±å¥½\" in msg:\n",
    "        stats = result.get('memory_stats')\n",
    "        if isinstance(stats, dict) and 'key_info' in stats and 'recent_messages' in stats:\n",
    "            print(f\"ğŸ“Š å…³é”®ä¿¡æ¯: {stats['key_info']}, è®°å¿†æ¶ˆæ¯: {stats['recent_messages']}\")\n",
    "        else:\n",
    "            print(\"ğŸ“Š å…³é”®ä¿¡æ¯: ï¼ˆæ— ç»Ÿè®¡æ•°æ®ï¼‰\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ€§èƒ½å¯¹æ¯”åˆ†æ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®¡ç®—æ€§èƒ½æŒ‡æ ‡\n",
    "def calculate_metrics(results):\n",
    "    tokens = [r.get('tokens_used', 0) for r in results if 'tokens_used' in r]\n",
    "    return {\n",
    "        'total_tokens': sum(tokens),\n",
    "        'avg_tokens': sum(tokens) / len(tokens) if tokens else 0,\n",
    "        'conversation_count': len(results)\n",
    "    }\n",
    "\n",
    "simple_metrics = calculate_metrics(simple_results)\n",
    "window_metrics = calculate_metrics(window_results)\n",
    "keyinfo_metrics = calculate_metrics(keyinfo_results)\n",
    "\n",
    "# åˆ›å»ºå¯¹æ¯”è¡¨æ ¼\n",
    "comparison_data = {\n",
    "    \"ç­–ç•¥\": [\"æ— è®°å¿†\", \"æ»‘åŠ¨çª—å£\", \"å…³é”®ä¿¡æ¯\"],\n",
    "    \"æ€»Token\": [simple_metrics['total_tokens'], window_metrics['total_tokens'], keyinfo_metrics['total_tokens']],\n",
    "    \"å¹³å‡Token/æ¬¡\": [simple_metrics['avg_tokens'], window_metrics['avg_tokens'], keyinfo_metrics['avg_tokens']],\n",
    "    \"è®°å¿†æŒä¹…æ€§\": [\"æ— \", \"çŸ­æœŸ\", \"é•¿æœŸ\"],\n",
    "    \"ä¿¡æ¯ä¿ç•™\": [\"ä½\", \"ä¸­ç­‰\", \"é«˜\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(comparison_data)\n",
    "print(\"ğŸ“ˆ æ€§èƒ½å¯¹æ¯”åˆ†æ:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# å¯è§†åŒ–å¯¹æ¯”\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. æ€»Tokenä½¿ç”¨å¯¹æ¯”\n",
    "ax1.bar(comparison_data[\"ç­–ç•¥\"], comparison_data[\"æ€»Token\"], color=['lightgray', 'skyblue', 'lightgreen'])\n",
    "ax1.set_title(\"æ€»Tokenä½¿ç”¨å¯¹æ¯”\")\n",
    "ax1.set_ylabel(\"Tokenæ•°é‡\")\n",
    "\n",
    "# 2. å¹³å‡Tokenä½¿ç”¨å¯¹æ¯”\n",
    "ax2.bar(comparison_data[\"ç­–ç•¥\"], comparison_data[\"å¹³å‡Token/æ¬¡\"], color=['lightgray', 'skyblue', 'lightgreen'])\n",
    "ax2.set_title(\"å¹³å‡Tokenä½¿ç”¨/æ¬¡å¯¹æ¯”\")\n",
    "ax2.set_ylabel(\"Tokenæ•°é‡\")\n",
    "\n",
    "# 3. è®°å¿†æŒä¹…æ€§è¯„åˆ†\n",
    "memory_scores = [1, 3, 5]  # æ— è®°å¿†=1, çŸ­æœŸ=3, é•¿æœŸ=5\n",
    "ax3.bar(comparison_data[\"ç­–ç•¥\"], memory_scores, color=['lightgray', 'skyblue', 'lightgreen'])\n",
    "ax3.set_title(\"è®°å¿†æŒä¹…æ€§è¯„åˆ†\")\n",
    "ax3.set_ylabel(\"è¯„åˆ† (1-5)\")\n",
    "ax3.set_ylim(0, 6)\n",
    "\n",
    "# 4. ä¿¡æ¯ä¿ç•™è¯„åˆ†\n",
    "info_scores = [1, 3, 5]  # ä½=1, ä¸­ç­‰=3, é«˜=5\n",
    "ax4.bar(comparison_data[\"ç­–ç•¥\"], info_scores, color=['lightgray', 'skyblue', 'lightgreen'])\n",
    "ax4.set_title(\"ä¿¡æ¯ä¿ç•™è¯„åˆ†\")\n",
    "ax4.set_ylabel(\"è¯„åˆ† (1-5)\")\n",
    "ax4.set_ylim(0, 6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ® äº’åŠ¨å®éªŒåŒº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨è¿™é‡Œè¿›è¡Œä½ è‡ªå·±çš„å®éªŒï¼\n",
    "# å°è¯•ä¸åŒçš„å¯¹è¯åœºæ™¯ï¼Œæµ‹è¯•è®°å¿†ç­–ç•¥çš„æ•ˆæœ\n",
    "\n",
    "# ç¤ºä¾‹ï¼šæµ‹è¯•é•¿å¯¹è¯ä¸­çš„ä¿¡æ¯ä¿æŒ\n",
    "long_dialogue = [\n",
    "    \"æˆ‘æ˜¯ç‹æ•™æˆï¼Œåœ¨æ¸…åå¤§å­¦æ•™è®¡ç®—æœºç§‘å­¦ã€‚\",\n",
    "    \"æˆ‘ç ”ç©¶äººå·¥æ™ºèƒ½å·²ç»æœ‰15å¹´äº†ã€‚\",\n",
    "    \"æˆ‘ä¸»è¦å…³æ³¨æ·±åº¦å­¦ä¹ å’Œè‡ªç„¶è¯­è¨€å¤„ç†ã€‚\",\n",
    "    \"æˆ‘å†™è¿‡3æœ¬ä¹¦ï¼Œå‘è¡¨äº†50å¤šç¯‡è®ºæ–‡ã€‚\",\n",
    "    \"æˆ‘æŒ‡å¯¼äº†20å¤šä¸ªç ”ç©¶ç”Ÿã€‚\",\n",
    "    \"æˆ‘çš„çˆ±å¥½æ˜¯å¤å…¸éŸ³ä¹å’Œå›´æ£‹ã€‚\",\n",
    "    \"æˆ‘ä¼šå¼¹é’¢ç´ï¼Œä¹Ÿå–œæ¬¢çˆ¬å±±ã€‚\",\n",
    "    \"æˆ‘æœ‰ä¸€ä¸ªå¥³å„¿æ­£åœ¨ä¸Šé«˜ä¸­ã€‚\",\n",
    "    \"æˆ‘å¤ªå¤ªæ˜¯ä¸€ååŒ»ç”Ÿã€‚\",\n",
    "    \"æˆ‘ä½åœ¨æ¸…åå¤§å­¦çš„æ•™å¸ˆå…¬å¯“ã€‚\"\n",
    "]\n",
    "\n",
    "test_questions = [\n",
    "    \"æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\",\n",
    "    \"æˆ‘åœ¨å“ªé‡Œå·¥ä½œï¼Ÿ\",\n",
    "    \"æˆ‘çš„ç ”ç©¶é¢†åŸŸæ˜¯ä»€ä¹ˆï¼Ÿ\",\n",
    "    \"æˆ‘æœ‰ä»€ä¹ˆçˆ±å¥½ï¼Ÿ\",\n",
    "    \"æˆ‘å†™äº†å¤šå°‘æœ¬ä¹¦ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "print(\"ğŸ§ª é•¿å¯¹è¯ä¿¡æ¯ä¿æŒæµ‹è¯•\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# é€‰æ‹©ä½ æƒ³è¦æµ‹è¯•çš„ç­–ç•¥\n",
    "print(\"é€‰æ‹©æµ‹è¯•ç­–ç•¥ (1-3):\")\n",
    "print(\"1. å…³é”®ä¿¡æ¯è®°å¿†\")\n",
    "print(\"2. æ»‘åŠ¨çª—å£è®°å¿†\")\n",
    "print(\"3. ç®€å•åŠ©æ‰‹\")\n",
    "\n",
    "# å–æ¶ˆæ³¨é‡Šä»¥ä¸‹ä»£ç è¿›è¡Œäº’åŠ¨æµ‹è¯•\n",
    "choice = input(\"è¯·è¾“å…¥é€‰æ‹©: \")\n",
    "\n",
    "if choice == \"1\":\n",
    "    agent = KeyInfoChatAgent(window_size=3)\n",
    "    strategy = \"å…³é”®ä¿¡æ¯è®°å¿†\"\n",
    "elif choice == \"2\":\n",
    "    agent = MemoryChatAgent(window_size=5)\n",
    "    strategy = \"æ»‘åŠ¨çª—å£è®°å¿†\"\n",
    "else:\n",
    "    agent = SimpleChatAgent()\n",
    "    strategy = \"ç®€å•åŠ©æ‰‹\"\n",
    "\n",
    "print(f\"\\nğŸ¯ ä½¿ç”¨ç­–ç•¥: {strategy}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# å…ˆè¿›è¡Œé•¿å¯¹è¯\n",
    "for msg in long_dialogue:\n",
    "    agent.chat(msg)\n",
    "\n",
    "# å†æµ‹è¯•è®°å¿†ä¿æŒ\n",
    "for question in test_questions:\n",
    "    print(f\"\\né—®é¢˜: {question}\")\n",
    "    result = agent.chat(question)\n",
    "    print(f\"å›ç­”: {result.get('response', result.get('error', 'Unknown error'))}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ æç¤ºï¼šå–æ¶ˆæ³¨é‡Šä¸Šé¢çš„ä»£ç è¿›è¡Œäº’åŠ¨æµ‹è¯•ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ å®éªŒæ€»ç»“ä¸æ€è€ƒ\n",
    "\n",
    "### ğŸ” å®éªŒå‘ç°\n",
    "\n",
    "é€šè¿‡ä¸Šé¢çš„å¯¹æ¯”å®éªŒï¼Œä½ å¯èƒ½å‘ç°ï¼š\n",
    "\n",
    "1. **æ— è®°å¿†åŠ©æ‰‹**ï¼šæ¯æ¬¡å¯¹è¯éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œæ— æ³•ä¿æŒä¸Šä¸‹æ–‡\n",
    "2. **æ»‘åŠ¨çª—å£è®°å¿†**ï¼šèƒ½ä¿æŒæœ€è¿‘å¯¹è¯ï¼Œä½†å¯èƒ½ä¸¢å¤±æ—©æœŸé‡è¦ä¿¡æ¯\n",
    "3. **å…³é”®ä¿¡æ¯è®°å¿†**ï¼šèƒ½é•¿æœŸä¿å­˜é‡è¦ä¿¡æ¯ï¼Œä½†éœ€è¦é¢å¤–çš„Tokenå¼€é”€\n",
    "\n",
    "### âš–ï¸ æƒè¡¡è€ƒè™‘\n",
    "\n",
    "| ç­–ç•¥ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |\n",
    "|------|------|------|----------|\n",
    "| æ— è®°å¿† | Tokenå°‘ã€å“åº”å¿« | æ— è®°å¿†èƒ½åŠ› | ç®€å•é—®ç­” |\n",
    "| æ»‘åŠ¨çª—å£ | å¹³è¡¡æ€§å¥½ | å¯èƒ½ä¸¢å¤±ä¿¡æ¯ | çŸ­æœŸå¯¹è¯ |\n",
    "| å…³é”®ä¿¡æ¯ | ä¿¡æ¯ä¿æŒå¥½ | Tokenå¼€é”€å¤§ | é•¿æœŸå…³ç³» |\n",
    "\n",
    "### ğŸš€ ä¼˜åŒ–æ–¹å‘\n",
    "\n",
    "1. **æ··åˆç­–ç•¥**ï¼šç»“åˆæ»‘åŠ¨çª—å£å’Œå…³é”®ä¿¡æ¯æå–\n",
    "2. **åŠ¨æ€çª—å£**ï¼šæ ¹æ®å¯¹è¯å¤æ‚åº¦è°ƒæ•´çª—å£å¤§å°\n",
    "3. **æ™ºèƒ½å‹ç¼©**ï¼šç”¨æ›´å°‘Tokenè¡¨è¾¾ç›¸åŒä¿¡æ¯\n",
    "4. **åˆ†å±‚è®°å¿†**ï¼šåŒºåˆ†çŸ­æœŸè®°å¿†å’Œé•¿æœŸè®°å¿†\n",
    "\n",
    "### ğŸ¯ å®è·µå»ºè®®\n",
    "\n",
    "- çŸ­å¯¹è¯ï¼šä½¿ç”¨æ»‘åŠ¨çª—å£ï¼ˆwindow_size=3-5ï¼‰\n",
    "- é•¿æœŸå…³ç³»ï¼šä½¿ç”¨å…³é”®ä¿¡æ¯è®°å¿†\n",
    "- æˆæœ¬æ•æ„Ÿï¼šå‡å°çª—å£å¤§å°æˆ–ä½¿ç”¨æ··åˆç­–ç•¥\n",
    "- ä¿¡æ¯å¯†é›†ï¼šå¢åŠ çª—å£å¤§å°æˆ–ä½¿ç”¨å…³é”®ä¿¡æ¯æå–\n",
    "\n",
    "### ğŸ¤” æ€è€ƒé¢˜\n",
    "\n",
    "1. å¦‚ä½•è¯„ä¼°ä¿¡æ¯çš„é‡è¦æ€§ï¼Ÿ\n",
    "2. æ€æ ·åœ¨ä¿æŒè®°å¿†å’Œæ§åˆ¶æˆæœ¬ä¹‹é—´æ‰¾åˆ°æœ€ä½³å¹³è¡¡ï¼Ÿ\n",
    "3. è¿˜æœ‰å“ªäº›åˆ›æ–°çš„è®°å¿†ç®¡ç†ç­–ç•¥ï¼Ÿ\n",
    "\n",
    "## ğŸ‰ å®éªŒå®Œæˆï¼\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†Agentè®°å¿†ä¼˜åŒ–çš„æ·±å…¥å®éªŒï¼ç°åœ¨ä½ å¯¹Agentçš„è®°å¿†ç®¡ç†æœ‰äº†æ›´æ·±å…¥çš„ç†è§£ã€‚ä¸‹ä¸€é˜¶æ®µå°†å­¦ä¹ å¦‚ä½•è®©Agentè°ƒç”¨å¤–éƒ¨å·¥å…·ï¼Œæ•¬è¯·æœŸå¾…ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myAgent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
